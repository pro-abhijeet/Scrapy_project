# -*- coding: utf-8 -*-
"""Information.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gpv7FWwFRRxekTnIlxtaWUCc6EBsoaP9
"""

from concurrent.futures import process
import scrapy
from scrapy_playwright.page import PageCoroutine
from scrapy.crawler import CrawlerProcess
import json
import pandas as pd

f = open('x.json')
#f = open('/scrapy_demo/clicking/clicking/spiders/x.json')
data = json.load(f)
data = data
course_list = []

for i in data:
    for k in range(len(i['main']['course_categories'])):
        for s in range(len(i['main']['course_categories'][k]['course_sub_categories'])):
            for j in i['main']['course_categories'][k]['course_sub_categories'][s]['courses']:
                course_list.append(j['online_title'])
print(course_list)


class InfoSpider(scrapy.Spider):
    name = 'info'
    start_urls = ['https://www.codingninjas.com/']
    headers = {
        "Accept" : "application/json",
        "Referer" : "https://www.codingninjas.com/",
        "sec-ch-ua" : '"Google Chrome";v="105", "Not)A;Brand";v="8", "Chromium";v="105"',
        "sec-ch-ua-mobile" : "?0",
        "sec-ch-ua-platform" : "Windows",
        "User-Agent" : "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36"
    }
    
 

    def parse(self, response):
        for course in course_list:

            i_url = 'https://api.codingninjas.com/api/v4/course/course_data?title={c}'.format(c=course)
            c_url = 'https://api.codingninjas.com/api/v4/course/course_plans?title={c}&marketing_token=03ad65c9c928411475414dd0ad8720be&ab_test_groups='.format(c=course)
            yield scrapy.Request(url=i_url, callback=self.parse_info, headers=self.headers)
            yield scrapy.Request(url=c_url, callback=self.parse_course, headers=self.headers)

    def parse_info(self, response):
        data = response.json()
        #data = json.loads(raw_data)
        yield{
            'info' : data["data"]
        }
    
    def parse_course(self, response):
        data = response.json()
        yield{
            'features' : data['data']
        }

process = CrawlerProcess(settings={
    'FEED_URI' : 'try.json',
    'FEED_FORMAT' : 'json'
})
process.crawl(InfoSpider)
process.start()

#----------------------- Formatting -----------------------#
f1 = open('/content/coding.json')
data_c = json.load(f1)
data_c

"""### MAIN"""

fees = []
date = []
features = []
special_features = []
faq_title = []
faq_desc = []
faq_ques = []
faq_description = []
course_title = []
rating = []
projects = []
problems = []
months = []
hours = []
stud_enrolled = []
fac_name = []
fac_desig = []
placement_assis = []
modules = []
sub_mod = []
l = []
sub_mod = []
course_curr = []
stud_name = []
stud_review = []
student_name = []
student_review = []

len(data_c)

for i in range(len(data_c)):
  for j in data_c[i]:
    print(j)
    # for  in data_c[i][1]['features']['course_products_groups'][0]['small_course_products_map']:
    #   print(j)

# Fees
try:
  for i in data_c[1]['features']['course_products_groups'][0]['small_course_products_map']['english']['earliest_batches']:
    fees.append(i['fees_with_tax'])
except:
  for i in data_c[1]['features']['course_products_groups'][0]['small_course_products_map']['hinglish']['earliest_batches']:
    fees.append(i['fees_with_tax'])
try:
  for i in data_c[1]['features']['course_products_groups'][0]['small_course_products_map']['english']['highest_discount_batches']:
    date.append(i['start_date'])
except:
  pass
  # for i in data_c[1]['features']['course_products_groups'][0]['small_course_products_map']['hinglish']['highest_discount_batches']:
  #   date.append(i['start_date'])

# Special Features
for i in data_c[1]['features']['course_products_groups'][0]['metadata']['special_features']:
  if i['covered'] == True:
    features.append(i['alt'])

print(fees, date, features)

special_features.append('|'.join(features))
special_features

"""## INFO"""

for i in data_c[0]['info']['course_data']['faqs']:
  faq_title.append(i['faq_title'])
  faq_desc.append([i['faq_description']])

for i in faq_desc:
  print(i)

"""### MAIN"""

faq_ques.append('|'.join(faq_title))
d = ''
for i in faq_desc:
  d += i[0] + '|'
faq_description.append(d)

print(faq_ques)
print(faq_description)



"""### MAIN"""

for i in data_c[0]['info']['course_data']['intro_section']['course_title']:
  # print(i)
  course_title.append(i)
course_title[0]

for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']:
  for j in i['duration']:
    print(j)

"""### MAIN"""

for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']['duration']:
  months.append(i)
try:
  for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']['projects_count']:
    projects.append(i)
except:
  try:
    for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']['problems']:
      problems.append(i)
  except:
    for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']['problem_count']:
      problems.append(i)
for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']['course_rating']:
  rating.append(i)
for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']['video_content_length']:
  hours.append(i)
for i in data_c[0]['info']['course_data']['intro_section']['course_metrics']['students_enrolled']:
  stud_enrolled.append(i)

months = months[0:2]
print(rating, projects, problems, months, hours, stud_enrolled)

for i in data_c[0]['info']['course_data']['support_system']['faculty']:
  fac_name.append(i['name'])
  fac_desig.append(i['designation'])

print(fac_name, fac_desig)

"""### MAIN"""

faculty_name = []
faculty_designation = []

faculty_name.append('|'.join(fac_name))
faculty_designation.append('|'.join(fac_desig))

print(faculty_name)
print(faculty_designation)

for i in data_c[0]['info']['course_data']['course_curriculum']['tab_data']:
  if i['title'] != 'Special Features':
    modules.append(i['title'])
  # for s in j['sections']:
  #   print(s)
modules

for i in data_c[0]['info']['course_data']['course_curriculum']['tab_data']:
  for m in modules:
    if i['title'] == m:
      for c in i['sections']:
        l.append(c['section_title'])
      sub_mod.append(l)
      l = []

modlist = list()
modulenum = 1
for j in modules:
    module = f"<p><strong>Module {modulenum}: {j}</strong>"
    modlist.append(module)
    submodnum = 1
    for i in range(len(sub_mod)):
      for k in (sub_mod[i]):
        submodule = f"<br/>{submodnum}. {k}"
        submodnum += 1
        modlist.append(submodule)
#         print("------------")
    modulenum += 1

    modlist.append('</p>')
       
content = "".join(modlist)

print(content)

course_curr.append(content)

for i in data_c[0]['info']['course_data']['testimonials']:
  stud_name.append(i['name'])
  stud_review.append([i['review']])
print(stud_name, stud_review)

"""### MAIN"""

student_name.append('|'.join(stud_name))
d = ''
for i in stud_review:
  d += i[0] + '|'
student_review.append(d)

print(student_name)
print(student_review)

if 'placement' or 'placement assistance' in data_c:
  placement_assis.append('True')
print(placement_assis)

dict1 = {
    'course_title' : course_title,
    'rating' : rating,
    'projects' : projects,
    'problems' : problems,
    'months' : months,
    'hours' : hours,
    'stud_enrolled' : stud_enrolled,
    'fees' : fees,
    'date' : date,
    'features' : special_features,
    'course_curr' : course_curr,
    'faq_ques' : faq_ques,
    'faq_description': faq_description,
    'placement_assistance' : placement_assis,
    'student_name' : student_name,
    'student_review' : student_review
}
dict1

# d1 = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in dict1.items() ]))
# d1

d2 = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in dict1.items() ]))
d2

d2.to_csv('dj_o.csv')