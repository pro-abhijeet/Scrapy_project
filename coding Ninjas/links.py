# -*- coding: utf-8 -*-
"""Links.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AqX2qSgw6z0ESEr5ifAFA9Vtnb49Erlw
"""

import imp
import scrapy
from scrapy_playwright.page import PageCoroutine
from scrapy.crawler import CrawlerProcess
import json

class MainSpider(scrapy.Spider):
    name = 'main'
    start_urls = ['https://www.codingninjas.com/']
    headers = {
        "Accept" : "application/json",
        "Referer" : "https://www.codingninjas.com/",
        "sec-ch-ua" : '"Google Chrome";v="105", "Not)A;Brand";v="8", "Chromium";v="105"',
        "sec-ch-ua-mobile" : "?0",
        "sec-ch-ua-platform" : "Windows",
        "User-Agent" : "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36"
    }
    
    def parse(self, response):
        link = 'https://api.codingninjas.com/api/v4/course/courses_info'
        yield scrapy.Request(url=link, callback=self.parse_main, headers=self.headers)

    def parse_main(self, response):
        data = response.json()
        yield{
            'main' : data['data']
        }

process = CrawlerProcess(settings={
    'FEED_URI' : 'x.json',
    'FEED_FORMAT' : 'json'
})
process.crawl(MainSpider)
process.start()